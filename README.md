# Evaluation of Scientific Elements for Text Similarity in Biomedical Publications

Data for the publication "Evaluation of Scientific Elements for Text Similarity in Biomedical Publications" published in the [6th Workshop on Argument Mining](https://argmining19.webis.de/) at [ACL 2019](http://www.acl2019.org/EN/index.xhtml).

The datasets that we annotated using three degrees of similarity are the .tsv files. 
**Currently, only four of the datasets are available, the remaining three will be released shortly.**

The annotations provided by the four tools that we tried, e.g., [Achakulvisut et al.](https://github.com/titipata/detecting-scientific-claim), [ArguminSci](https://github.com/anlausch/ArguminSci), [MAZEA](http://www.nilc.icmc.usp.br/mazea-web/), and [Prasad and Kan](https://github.com/animeshprasad/science_ie), are the .zip files. All annotations uses the [PubAnnotation JSON format](http://www.pubannotation.org/docs/annotation-format/).

The list of PMIDs are returned by [PubMed Similar Articles](https://www.nlm.nih.gov/bsd/disted/pubmedtutorial/020_190.html) are the pubmed.txt files.

Please cite our publication if you use our data, citation coming soon.
